# -*- coding: utf-8 -*-
"""Document Analyser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v3qVWt738W6dlcjH4RMGIjXsB67-ecjw
"""

# üì¶ Install all dependencies
!apt-get install -y tesseract-ocr poppler-utils
!pip install pytesseract pdf2image opencv-python Pillow

# üìÇ Upload documents (images or PDFs)
from google.colab import files
uploaded = files.upload()

'''import pytesseract
from pdf2image import convert_from_path
from PIL import Image
import cv2
import os

# üîë Keyword map for classification
DOCUMENT_KEYWORDS = {
    "Aadhar card": ["uidai", "aadhar", "unique identification",r'\b\d{4}\s?\d{4}\s?\d{4}\b'],
    "Community certificate": ["community certificate", "caste", "scheduled caste", "scheduled tribe"],
    "Income certificate": ["income certificate", "annual income"],
    "Nativity certificate": ["nativity certificate", "native of"],
    "OBC certificate": ["obc", "other backward class"],
    "Person With Benchmark Disability (PwBD) Certificate": ["disability certificate", "benchmark disability", "pwbd"],
    "License": ["driving license", "dl no", "licence"],
    "Voter ID": ["election commission", "voter id", "epic"],
    "Passport": ["passport", "republic of india"],
    "Passport size photo": ["passport photo", "photo size"],
    "Thumb Impression": ["thumb impression", "fingerprint"],
    "Scanned signature": ["signature", "signed by"],
    "10th marksheet": ["10th", "ssc", "secondary school", "matriculation", "secondary school leaving certifcate"],
    "11th marksheet": ["11th", "higher secondary", "plus one"],
    "12th marksheet": ["higher secondary course ", "second year mark certificate", "hr sec", "higher secondary", "plus two"],
    "Birth certificate": ["birth certificate", "date of birth", "place of birth"]
}

# üß† Extract text from PDF or image
def extract_text_from_file(file_path):
    ext = os.path.splitext(file_path)[-1].lower()
    text = ""

    if ext == ".pdf":
        images = convert_from_path(file_path, dpi=300, size=(1654, 2339))  # A4 size at 300dpi
        for img in images[:2]:  # Only process first 2 pages
            img_gray = img.convert("L")  # convert to grayscale
            img_bw = img_gray.point(lambda x: 0 if x < 140 else 255, '1')  # binarize
            text += pytesseract.image_to_string(img_bw)
    elif ext in [".jpg", ".jpeg", ".png", ".bmp", ".tiff"]:
        image = cv2.imread(file_path)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        # ‚úÖ Apply threshold to improve clarity
        gray = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
        text = pytesseract.image_to_string(gray)
    else:
        print(f"Unsupported file format: {ext}")

    return text.lower()
def classify_document(text):
    # Check for Aadhar card (12-digit number)
    aadhar_pattern = re.compile(r'\b\d{4}\s?\d{4}\s?\d{4}\b')
    if aadhar_pattern.search(text):
        return 'aadhar_card'

    # Keyword-based classification
    for doc_type, keywords in DOCUMENT_KEYWORDS.items():
        if any(keyword in text for keyword in keywords):
            return doc_type

    return "unknown_document"

# üìÑ Match keywords to determine document type
def identify_document(text):
    for doc_type, keywords in DOCUMENT_KEYWORDS.items():
        if any(keyword in text for keyword in keywords):
            return doc_type
    return "Unknown_Document"

# ‚úèÔ∏è Rename file based on identified document
def rename_file(original_path, doc_type):
    base, ext = os.path.splitext(original_path)
    new_name = doc_type.replace(" ", "_") + ext
    os.rename(original_path, new_name)
    return new_name
'''

import pytesseract
from pdf2image import convert_from_path
import cv2
import os
import re
from typing import Dict, List, Optional

# üîë Pre-compiled regex patterns for faster matching
DOCUMENT_KEYWORDS = {
    "Aadhar card": [re.compile(pattern, re.IGNORECASE) for pattern in
                   ["uidai", "aadhar", "unique identification", r'\b\d{4}\s?\d{4}\s?\d{4}\b']],
    "Community certificate": [re.compile(pattern, re.IGNORECASE) for pattern in
                            ["community", "caste", "scheduled caste", "scheduled tribe", "MBC", "BC", "OC", "FC", "SC", "ST"]],
    "Income certificate": [re.compile(pattern, re.IGNORECASE) for pattern in
                          ["income certificate", "annual income"]],
    "Nativity certificate": [re.compile(pattern, re.IGNORECASE) for pattern in
                           ["nativity certificate", "native of"]],
    "OBC certificate": [re.compile(pattern, re.IGNORECASE) for pattern in
                       ["obc", "other backward class"]],
    "Person With Benchmark Disability (PwBD) Certificate": [re.compile(pattern, re.IGNORECASE) for pattern in
                                                          ["disability certificate", "benchmark disability", "pwbd"]],
    "License": [re.compile(pattern, re.IGNORECASE) for pattern in
               ["driving license", "dl no", "licence"]],
    "Voter ID": [re.compile(pattern, re.IGNORECASE) for pattern in
                ["election commission", "voter id", "epic"]],
    "Passport": [re.compile(pattern, re.IGNORECASE) for pattern in
                ["passport", "republic of india"]],
   ''' "Passport size photo": [re.compile(pattern, re.IGNORECASE) for pattern in
                           ["passport photo", "photo size"]],
    "Thumb Impression": [re.compile(pattern, re.IGNORECASE) for pattern in
                       ["thumb impression", "fingerprint"]],
    "Scanned signature": [re.compile(pattern, re.IGNORECASE) for pattern in
                        ["signature", "signed by"]], '''
    "10th marksheet": [re.compile(pattern, re.IGNORECASE) for pattern in
                      ["10th", "ssc", "secondary school", "matriculation", "secondary school leaving certifcate"]],
    "11th marksheet": [re.compile(pattern, re.IGNORECASE) for pattern in
                      ["11th", "higher secondary", "plus one"]],
    "12th marksheet": [re.compile(pattern, re.IGNORECASE) for pattern in
                      ["higher secondary course", "second year mark", "hr sec", "higher secondary", "plus two", "PERMANENT REGISTER NUMBER"]],
    "Birth certificate": [re.compile(pattern, re.IGNORECASE) for pattern in
                         ["birth certificate", "date of birth", "place of birth"]]
}

# Pre-compiled Aadhar pattern for quick check
AADHAR_PATTERN = re.compile(r'\b\d{4}\s?\d{4}\s?\d{4}\b')

def extract_text_from_file(file_path: str) -> str:
    """Optimized text extraction from PDF or image files."""
    ext = os.path.splitext(file_path)[-1].lower()
    text = ""

    try:
        if ext == ".pdf":
            # Convert only the first page for classification
            images = convert_from_path(file_path, dpi=200, first_page=1, last_page=1)
            if images:
                img = images[0]
                # Optimized preprocessing
                img = img.convert("L")  # Grayscale
                img = img.point(lambda x: 0 if x < 140 else 255)  # Binarization
                text = pytesseract.image_to_string(img, config='--psm 6')

        elif ext in (".jpg", ".jpeg", ".png", ".bmp", ".tiff"):
            # Read image with OpenCV in grayscale directly
            img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                # Adaptive thresholding works better than global for varied lighting
                img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
                text = pytesseract.image_to_string(img, config='--psm 6')
        else:
            print(f"Unsupported file format: {ext}")

    except Exception as e:
        print(f"Error processing {file_path}: {str(e)}")

    return text

def classify_document(text: str) -> str:
    """Optimized document classification with early returns."""
    if not text:
        return "unknown_document"

    # First check for Aadhar card (fast pattern match)
    if AADHAR_PATTERN.search(text):
        return "Aadhar card"

    # Then check other document types
    text_lower = text.lower()
    for doc_type, patterns in DOCUMENT_KEYWORDS.items():
        if any(pattern.search(text_lower) for pattern in patterns):
            return doc_type

    return "unknown_document"

def process_document(file_path: str) -> Optional[str]:
    """Process and rename document file."""
    try:
        text = extract_text_from_file(file_path)
        doc_type = classify_document(text)
        return rename_file(file_path, doc_type)
    except Exception as e:
        print(f"Error processing document {file_path}: {e}")
        return None

def rename_file(original_path: str, doc_type: str) -> str:
    """Rename file with document type."""
    dir_name = os.path.dirname(original_path)
    base_name = os.path.basename(original_path)
    base, ext = os.path.splitext(base_name)
    new_name = f"{doc_type.replace(' ', '_')}{ext}"
    new_path = os.path.join(dir_name, new_name)

    os.rename(original_path, new_path)
    return new_path

# üîç View OCR text for debugging
for filename in uploaded.keys():
    print(f"\nüßæ Extracting text from: {filename}")
    try:
        text = extract_text_from_file(filename)
        print("---- Extracted Text Start ----")
        print(text)
        print("---- Extracted Text End ----")
    except Exception as e:
        print(f"Error reading {filename}: {e}")

# üîÅ Run OCR + rename on all uploaded files
for filename in uploaded.keys():
    print(f"\nüîç Processing: {filename}")
    try:
        text = extract_text_from_file(filename)
        doc_type = classify_document(text)  # Changed from identify_document to classify_document
        new_filename = rename_file(filename, doc_type)
        print(f"‚úÖ Renamed as: {new_filename}")
    except Exception as e:
        print(f"‚ùå Failed to process {filename}: {e}")

'''
# üîÅ Optimized batch processing of uploaded files
def process_uploaded_files(uploaded_files: dict) -> dict:
    """
    Process all uploaded files through OCR, classification, and renaming.
    Returns a dictionary of {original_filename: new_filename} for successful processes.
    """
    results = {}

    for filename in uploaded_files.keys():
        print(f"\nüîç Processing: {filename}")
        try:
            # Extract text with optimized OCR
            text = extract_text_from_file(filename)

            # Skip empty/unreadable files
            if not text.strip():
                print(f"‚ö†Ô∏è  Empty text extracted from {filename} - skipping")
                continue

            # Classify document
            doc_type = classify_document(text)

            # Rename file
            new_filename = rename_file(filename, doc_type)
            results[filename] = new_filename
            print(f"‚úÖ Classified as: {doc_type}")
            print(f"‚úÖ Renamed to: {new_filename}")

        except pytesseract.TesseractError as te:
            print(f"‚ùå OCR Error processing {filename}: {str(te)}")
        except OSError as oe:
            print(f"‚ùå File Operation Error with {filename}: {str(oe)}")
        except Exception as e:
            print(f"‚ùå Unexpected error processing {filename}: {str(e)}")
            if hasattr(e, '__traceback__'):
                import traceback
                traceback.print_exc()

    # Print summary statistics
    print("\nüìä Processing Summary:")
    print(f"Total files: {len(uploaded_files)}")
    print(f"Successfully processed: {len(results)}")
    print(f"Failed: {len(uploaded_files) - len(results)}")

    return results

# ACTUALLY CALL THE FUNCTION TO EXECUTE IT
if __name__ == "__main__":
    # Example usage (replace with your actual uploaded files dict)
    uploaded = {
        "document1.pdf": None,
        "image1.jpg": None
    }

    processed_files = process_uploaded_files(uploaded)
    print("\nFinal results:", processed_files)

'''

